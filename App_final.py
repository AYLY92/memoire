{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "081d16b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting App.py\n"
     ]
    }
   ],
   "source": [
    "\n",
    "################################################################################################################################\n",
    "################################################ Importation des bibliothéques #################################################\n",
    "################################################################################################################################\n",
    "\n",
    "import streamlit as st\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "import seaborn as sns # Visualization\n",
    "import matplotlib.pyplot as plt # Visualization\n",
    "#from colorama import Fore\n",
    "\n",
    "from matplotlib import pyplot\n",
    "import plotly.offline as py\n",
    "import plotly.graph_objs as go\n",
    "from plotly.offline import iplot, init_notebook_mode\n",
    "from plotly.subplots import make_subplots\n",
    "from statsmodels.tsa.seasonal import DecomposeResult, seasonal_decompose\n",
    "\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import math\n",
    "\n",
    "from datetime import datetime,date,timedelta \n",
    "import datetime as dt\n",
    "import time\n",
    "\n",
    "import warnings # Supress warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "np.random.seed(7)\n",
    "import IPython\n",
    "from IPython.display import display\n",
    "import base64\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Dropout\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.models import load_model\n",
    "import tensorflow as tf\n",
    "import hydroeval as he\n",
    "\n",
    "\n",
    "import streamlit as st\n",
    "from streamlit_lottie import st_lottie\n",
    "from streamlit_option_menu import option_menu\n",
    "import streamlit.components.v1 as html\n",
    "from  PIL import Image\n",
    "import numpy as np\n",
    "import cv2\n",
    "import pandas as pd\n",
    "from st_aggrid import AgGrid\n",
    "import plotly.express as px\n",
    "import io \n",
    "\n",
    "\n",
    "\n",
    "py.init_notebook_mode(connected=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "################################################################################################################################\n",
    "########################################### hide streamlit components ##########################################################\n",
    "################################################################################################################################\n",
    "\n",
    "hide_menu_style = \"\"\" \n",
    "        <style> \n",
    "        #MainMenu {visibility : hidden; }\n",
    "        footer {visibility : hidden;}\n",
    "        </style>\n",
    "        \"\"\"\n",
    "st.markdown(hide_menu_style, unsafe_allow_html = True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "################################################################################################################################\n",
    "################################################ barre latérale ################################################################\n",
    "################################################################################################################################\n",
    "\n",
    "\n",
    "with st.sidebar:\n",
    "    choose = option_menu(\"App Prévisionnelle\", [\"Accueil\", \"Lstm\", \"Article\", \"Code source\"],\n",
    "                         icons=['house', 'clipboard-data', 'clipboard-data', 'clipboard-data'],\n",
    "                         menu_icon=\"app-indicator\",default_index=0, \n",
    "                         styles={                  \n",
    "        \"container\": {\"padding\": \"5!important\", \"background-color\": \"#fafafa\"},\n",
    "        \"icon\": {\"color\": \"orange\", \"font-size\": \"25px\"}, \n",
    "        \"nav-link\": {\"font-size\": \"16px\", \"text-align\": \"left\", \"margin\":\"0px\", \"--hover-color\": \"#eee\"},\n",
    "        \"nav-link-selected\": {\"background-color\": \"#3379FF\"},\n",
    "    }\n",
    "    )\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "################################################################################################################################\n",
    "################################################ page d'accueil ################################################################\n",
    "################################################################################################################################\n",
    "\n",
    "if choose == \"Accueil\":\n",
    "        \n",
    "        \n",
    "        \n",
    "        # To display the header text using css style\n",
    "        st.markdown(\"\"\" <style> .font {\n",
    "        font-size:35px ; font-family: 'Cooper Black'; color: #FF9633;} \n",
    "        </style> \"\"\", unsafe_allow_html=True)\n",
    "        st.markdown('<p class=\"font\">Accueil</p>', unsafe_allow_html=True)        \n",
    "        st.markdown(\"\"\"\n",
    "         Cette application a été conçue dans le but de prédire l'évolution du régime hydrolique du fleuve Sénégal.\n",
    "         Elle a été réalisée grâce à une variante des réseaux de neuronnes de récurrents. Il s'agit des réseau récurrent \n",
    "         à mémoire court et long terme ou plus explicitement les réseaux de neurones récurrents à mémoire court-terme \n",
    "         et long terme (LSTM: Long Short Term Memory).\"\"\")\n",
    "        \n",
    "        \n",
    "\n",
    "        \n",
    "\n",
    "        \n",
    "            \n",
    "        \n",
    "            \n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "################################################################################################################################\n",
    "################################################Lstm univarié ##################################################################\n",
    "################################################################################################################################    \n",
    "\n",
    "elif choose == \"Lstm\":\n",
    "    st.markdown(\"\"\" <style> .font {\n",
    "    font-size:35px ; font-family: 'Cooper Black'; color: #FF9633;} \n",
    "    </style> \"\"\", unsafe_allow_html=True)\n",
    "    st.markdown('<p class=\"font\">Lstm</p>', unsafe_allow_html=True)\n",
    "     \n",
    "    #with st.expander(label=\"Veuillez cliquer pour déplier/replier\"):\n",
    "        \n",
    "\n",
    "    station = ('','BAKEL', 'MATAM', 'PODOR')\n",
    "    selected_station = st.selectbox('Veuillez cliquer pour sélectionner une station', station, key =0)\n",
    "\n",
    "    ##############################################################################################\n",
    "    ## Traitement des données brutes\n",
    "    ##############################################################################################\n",
    "\n",
    "    if selected_station =='':\n",
    "\n",
    "        st.markdown('')\n",
    "    else:\n",
    "        #\n",
    "\n",
    "        #n_years = st.slider('Années prévisonnelles:', 1, 4)\n",
    "        #period = n_years * 365\n",
    "\n",
    "        ### Chargment des données\n",
    "        @st.cache\n",
    "        def readerfile():\n",
    "\n",
    "\n",
    "            if selected_station ==  'BAKEL':\n",
    "              data = pd.read_excel(\"https://github.com/AYLY92/memoire/blob/main/data/H_Bakel.xls\", nrows = 366)\n",
    "\n",
    "            elif selected_station ==  'MATAM':\n",
    "              data = pd.read_excel(\"https://github.com/AYLY92/memoire/blob/main/data/H_Matam.xls\", nrows = 366).drop('Unnamed: 49', 1)\n",
    "\n",
    "            else:\n",
    "              data = pd.read_excel(\"https://github.com/AYLY92/memoire/blob/main/data/H_Podor.xls\", nrows = 366).drop('Unnamed: 49', 1)\n",
    "\n",
    "            #data.reset_index(inplace=True)\n",
    "\n",
    "            return data\n",
    "\n",
    "\n",
    "\n",
    "        def configure_plotly_browser_state():\n",
    "\n",
    "            import IPython\n",
    "            display(IPython.core.display.HTML('''\n",
    "                  <script src =\"/static/components/requirejs/require.js\"></script>\n",
    "                  <script>\n",
    "                    requirejs.config({\n",
    "                      paths: {\n",
    "                        base:'/static/base',\n",
    "                        plotly:'https://cdn.plot.ly/plotly-1.5.1.min.js?noext',\n",
    "\n",
    "                      },\n",
    "                    ));\n",
    "                    </script>\n",
    "                    '''))\n",
    "\n",
    "        #Télécharment des fichiers sous format csv\n",
    "        #def filedownload(df):\n",
    "    \n",
    "        #    csv = df.to_csv(index=False)\n",
    "        #    b64 = base64.b64encode(csv.encode()).decode()\n",
    "        #    href = f'<a href=\"data:file/csv;base64,{b64}\" download =\"station.csv\">Télécharger le fichier CSV</a>'\n",
    "        #    return href\n",
    "        @st.cache\n",
    "        def convert_df(df):\n",
    "             # IMPORTANT: Cache the conversion to prevent computation on every rerun\n",
    "            return df.to_csv().encode('utf-8')\n",
    "\n",
    "        \n",
    "\n",
    "        data_load_state = st.text('Loading data...')\n",
    "        data = readerfile()\n",
    "        data_load_state.text('Loading data... done! ✔️')\n",
    "\n",
    "\n",
    "        st.markdown('''\n",
    "        ### Traitement des valeurs brutes\n",
    "        ''')\n",
    "        st.markdown('**Tableau des données brutes**')\n",
    "        st.write('Dimensions des données: ' + str(data.shape[0]) + ' lignes & ' + str(data.shape[1]) + ' colonnes')\n",
    "        st.write(data)\n",
    "        #st.markdown(filedownload(data), unsafe_allow_html=True)\n",
    "        csv = convert_df(data)\n",
    "        st.download_button(\n",
    "             label=\"Télécharger le tableau\",\n",
    "             data=csv,\n",
    "             file_name='data.csv',\n",
    "             mime='text/csv',\n",
    "         )\n",
    "\n",
    "        ### Prétraitement des données\n",
    "        @st.cache\n",
    "        def prepoocessing():\n",
    "            if selected_station ==  'BAKEL':\n",
    "              data = pd.read_csv(\"https://github.com/AYLY92/memoire/blob/main/data/df_bakel.csv\").drop(['Unnamed: 0', 'Unnamed: 0.1'], axis=1)\n",
    "              if data['hauteur'].isna().sum() != 0:\n",
    "                data['hauteur'] = data['hauteur'].interpolate()\n",
    "              if data['hauteur'].isna().sum() != 0:\n",
    "                data['hauteur'] = data['hauteur'].fillna(df['hauteur'].mean())\n",
    "\n",
    "            elif selected_station ==  'MATAM':\n",
    "              data = pd.read_csv(\"https://github.com/AYLY92/memoire/blob/main/data/df_matam.csv\").drop(['Unnamed: 0'], axis=1)\n",
    "              if data['hauteur'].isna().sum() != 0:\n",
    "                data['hauteur'] = data['hauteur'].interpolate()\n",
    "              if data['hauteur'].isna().sum() != 0:\n",
    "                data['hauteur'] = data['hauteur'].fillna(df['hauteur'].mean())\n",
    "\n",
    "            else:\n",
    "              data = pd.read_csv(\"https://github.com/AYLY92/memoire/blob/main/data/df_podor.csv\").drop(['Unnamed: 0'], axis=1)\n",
    "              if data['hauteur'].isna().sum() != 0:\n",
    "                data['hauteur'] = data['hauteur'].interpolate()\n",
    "              if data['hauteur'].isna().sum() != 0:\n",
    "                data['hauteur'] = data['hauteur'].fillna(data['hauteur'].mean())\n",
    "\n",
    "            #data.reset_index(inplace=True)\n",
    "\n",
    "            return data\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        data_load_state = st.text('Loading data...')\n",
    "        data = prepoocessing()\n",
    "        data_load_state.text('Loading data... done! ✔️')\n",
    "\n",
    "        st.markdown('**Tableau des données prétraitées**')\n",
    "        st.write('Dimensions des données: ' + str(data.shape[0]) + ' lignes & ' + str(data.shape[1]) + ' colonnes')\n",
    "        st.write(data)\n",
    "        csv = convert_df(data)\n",
    "        st.download_button(\n",
    "             label=\"Télécharger le tableau\",\n",
    "             data=csv,\n",
    "             file_name='data.csv',\n",
    "             mime='text/csv',\n",
    "         )\n",
    "        #st.markdown(filedownload(data), unsafe_allow_html=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        ### Visualisation\n",
    "        def plot_raw_data():\n",
    "\n",
    "            fig = go.Figure()\n",
    "            fig.add_trace(go.Scatter(x=data['date'], y=data['hauteur'].fillna(method='ffill')))\n",
    "            fig.layout.update(xaxis_rangeslider_visible=True, xaxis =dict(title = 'date'), yaxis = dict(title = \"hauteur d'eau\"))\n",
    "            st.plotly_chart(fig)\n",
    "\n",
    "        st.markdown(\"**Visualisation de l'évolution du régime hydrologique**\")\t\n",
    "        plot_raw_data()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        ## Traitement des données prédites\n",
    "        # renvoie un dateframe constitué de la colonne date et chacune des données de la station et les dimensions de décompositions\n",
    "        def creation_df(df, col_date, col_y, n):\n",
    "\n",
    "            train_size = int(n * len(df))\n",
    "            test_size = len(df) - train_size\n",
    "\n",
    "            univariate_df = df[[col_date, col_y]].copy()\n",
    "            return univariate_df, train_size, test_size\n",
    "\n",
    "\n",
    "        univariate_df, train_size, test_size = creation_df(data, 'date', 'hauteur', 0.85)\n",
    "\n",
    "\n",
    "        # Normalisation et division en données de train et de test\n",
    "        from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "        def normalize_data(df, col_y):\n",
    "            # Normalisation des données\n",
    "            data = df.filter([col_y])\n",
    "            dataset = data.values\n",
    "            scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "            scaled_data = scaler.fit_transform(dataset)\n",
    "\n",
    "\n",
    "            return scaled_data, scaler\n",
    "\n",
    "\n",
    "\n",
    "        scaled_data, scaler = normalize_data(univariate_df, 'hauteur')\n",
    "\n",
    "\n",
    "\n",
    "        # Split into train et test for scaled_data\n",
    "        def split_scaled_data(scaled_data, train_size, look_back):\n",
    "\n",
    "            train, test = scaled_data[:train_size-look_back,:], scaled_data[train_size-look_back:,:]\n",
    "            return train, test\n",
    "\n",
    "\n",
    "\n",
    "        train, test = split_scaled_data(scaled_data, train_size, 365)\n",
    "\n",
    "\n",
    "        # Création du dataset qui convertit un tableau de valeurs en une matrice de données.\n",
    "        def create_dataset(dataset, look_back):\n",
    "            X, Y = [], []\n",
    "            for i in range(look_back, len(dataset)):\n",
    "                a = dataset[i-look_back:i, 0]\n",
    "                X.append(a)\n",
    "                Y.append(dataset[i, 0])\n",
    "            return np.array(X), np.array(Y)\n",
    "\n",
    "        #Bakel\n",
    "        x_train, y_train = create_dataset(train, 365)\n",
    "        x_test, y_test = create_dataset(test, 365)\n",
    "\n",
    "\n",
    "        # remodeler l'entrée pour qu'elle soit [échantillons, pas de temps, caractéristiques].\n",
    "        def reshaping(x_train, x_test):\n",
    "            return np.reshape(x_train, (x_train.shape[0], 1, x_train.shape[1])), np.reshape(x_test, (x_test.shape[0], 1, x_test.shape[1]))\n",
    "\n",
    "        x_train, x_test = reshaping(x_train, x_test)\n",
    "\n",
    "        #load the save model\n",
    "        if selected_station ==  'BAKEL':\n",
    "            model = tf.keras.models.load_model('https://github.com/AYLY92/memoire/blob/main/data/best_model_bakel.h5')\n",
    "\n",
    "        elif selected_station ==  'MATAM':\n",
    "            model = tf.keras.models.load_model('https://github.com/AYLY92/memoire/blob/main/data/best_model_matam.h5')\n",
    "\n",
    "        else:\n",
    "            model = tf.keras.models.load_model('https://github.com/AYLY92/memoire/blob/main/data/best_model_podor.h5')\n",
    "\n",
    "        # Prédiction\n",
    "        def make_prediction(model, x_train, x_test, y_train, y_test, scaler):\n",
    "            # Lets predict with the model\n",
    "            train_predict = model.predict(x_train)\n",
    "            test_predict = model.predict(x_test)\n",
    "\n",
    "            # invert predictions\n",
    "            train_predict = scaler.inverse_transform(train_predict)\n",
    "            y_train = scaler.inverse_transform([y_train])\n",
    "\n",
    "            test_predict = scaler.inverse_transform(test_predict)\n",
    "            y_test = scaler.inverse_transform([y_test])\n",
    "\n",
    "            # Get the root mean squared error (RMSE) and MAE on test data\n",
    "            #score_rmse = np.sqrt(mean_squared_error(y_test[0], test_predict[:,0]))\n",
    "            score_nse = he.evaluator(he.nse, list(y_test[0]), list(test_predict[:,0]))[0]\n",
    "            score_mae = mean_absolute_error(y_test[0], test_predict[:,0])\n",
    "            #print('RMSE: {}'.format(score_rmse))\n",
    "            print('MAE: {}'.format(score_mae))\n",
    "            print('Nash: {}'.format(score_nse))\n",
    "\n",
    "            return score_nse, score_mae, y_test, test_predict\n",
    "\n",
    "        score_nse, score_mae, y_test, test_predict = make_prediction(model, x_train, x_test, y_train, y_test, scaler)\n",
    "\n",
    "\n",
    "        # Tableau comparatif des valeurs prédites vs valeurs réelles\n",
    "        def tab_prediction(df, test_size, y_test, test_predict):\n",
    "            x_test_ticks = df.tail(test_size)['date']\n",
    "            y = y_test[0]\n",
    "            y_pred = test_predict[:,0]\n",
    "            return pd.DataFrame({'date': x_test_ticks, 'Test Set': y, 'Predict on Test Set': y_pred})\n",
    "\n",
    "        #Test Set\n",
    "        st.markdown('**Tableau Test Set vs Prediction on Test Set**')\n",
    "        tab_test = tab_prediction(univariate_df, test_size, y_test, test_predict)\n",
    "        st.write('Dimensions des données: ' + str(tab_test.shape[0]) + ' lignes & ' + str(tab_test.shape[1]) + ' colonnes')\n",
    "        st.write(tab_test)\n",
    "        csv = convert_df(tab_test)\n",
    "        st.download_button(\n",
    "             label=\"Télécharger le tableau\",\n",
    "             data=csv,\n",
    "             file_name='tab_test.csv',\n",
    "             mime='text/csv',\n",
    "         )\n",
    "        #st.markdown(filedownload(tab_test), unsafe_allow_html=True)\n",
    "        st.write('MAE  : ' + str(score_mae)) \n",
    "        st.write('NASH : ' + str(score_nse))\n",
    "\n",
    "\n",
    "\n",
    "        # Visualisation de la prédiction\n",
    "        def visualisation_prediction(df, train_size, test_size, y_test, test_predict):\n",
    "\n",
    "            x_train_ticks = df.head(train_size)['date']\n",
    "            y_train = df.head(train_size)['hauteur']\n",
    "            x_test_ticks = df.tail(test_size)['date']\n",
    "\n",
    "            fig = go.Figure()\n",
    "            fig.add_trace(go.Scatter(x=x_train_ticks, y=y_train, name='Train Set'))\n",
    "            fig.add_trace(go.Scatter(x=x_test_ticks, y=test_predict[:,0],  name= \"Prediction on Test Set\"))\n",
    "            fig.add_trace(go.Scatter(x=x_test_ticks, y=y_test[0], name = \"Test Set\"))\n",
    "            fig.layout.update( {\"title\":\"Hauteur d'eau prédite vs réelle\",\n",
    "                      \"xaxis\":{\"title\": 'date',\n",
    "                               \"zeroline\":False},\n",
    "                      \"yaxis\":{\"title\":'hauteur',\n",
    "                               \"zeroline\":False}} )\n",
    "            st.plotly_chart(fig) \n",
    "\n",
    "        st.markdown(\"**Visualisation des valeurs prédites sur les données d'entrainement et de test**\")\n",
    "        visualisation_prediction(univariate_df, train_size, test_size,  y_test, test_predict)\n",
    "\n",
    "        #  future prediction\n",
    "        def futur_prediction(model, test_data, look_back,  nday):\n",
    "\n",
    "            from numpy import array\n",
    "            x_input = scaler.inverse_transform(test_data[len(test_data) - look_back:].reshape(1, -1))\n",
    "            temp_input=list(x_input)\n",
    "            temp_input=temp_input[0].tolist()\n",
    "\n",
    "            lst_output=[]\n",
    "            #look_back=365\n",
    "            i=0\n",
    "            while(i<nday):\n",
    "\n",
    "                if(len(temp_input)>look_back):\n",
    "                    #print(temp_input)\n",
    "                    x_input=np.array(temp_input[1:])\n",
    "                    #print(\"{} day input {}\".format(i,x_input))\n",
    "                    x_input=x_input.reshape(1, -1)\n",
    "                    x_input = x_input.reshape((1, 1, look_back))\n",
    "                    #print(x_input)\n",
    "                    yhat = model.predict(x_input, verbose=0)\n",
    "                    yhat = scaler.inverse_transform(yhat)\n",
    "                    #print(\"{} day output {}\".format(i,yhat))\n",
    "                    temp_input.extend(yhat[0].tolist())\n",
    "                    temp_input=temp_input[1:]\n",
    "                    #print(temp_input)\n",
    "                    lst_output.extend(yhat.tolist())\n",
    "                    i=i+1\n",
    "                else:\n",
    "                    x_input = x_input.reshape((1,  1, look_back))\n",
    "                    yhat = model.predict(x_input, verbose=0)\n",
    "                    yhat = scaler.inverse_transform(yhat)\n",
    "                    #print(yhat[0])\n",
    "                    temp_input.extend(yhat[0].tolist())\n",
    "                    #print(len(temp_input))\n",
    "                    lst_output.extend(yhat.tolist())\n",
    "                    i=i+1\n",
    "\n",
    "            lst_output = pd.DataFrame(lst_output, columns= ['hauteur'])\n",
    "            day_pred =  pd.DataFrame(pd.date_range('2008-05-01', periods=nday, freq='1D').tolist(), columns=['date'])\n",
    "            pred_station = pd.concat([day_pred, pd.DataFrame(lst_output).iloc[:,0]], 1)\n",
    "\n",
    "            return pred_station\n",
    "\n",
    "        ##############################################################################################\n",
    "        ## Traitement des valeurs prédites\n",
    "        ##############################################################################################\n",
    "        st.markdown('''\n",
    "        ### Traitement des valeurs predites\n",
    "        ''')\n",
    "        # nombre d'année à prédire\n",
    "        period = st.number_input(\n",
    "        label=\"Insérer le nombre de jours à prédire\",\n",
    "        min_value=0,\n",
    "        step=1, key=0)\n",
    "\n",
    "        if period == 0:\n",
    "\n",
    "            st.markdown('')\n",
    "\n",
    "        else:\n",
    "\n",
    "            data_load_state = st.text('Loading data...')\n",
    "            nday = period\n",
    "            pred_station = futur_prediction(model, test, 365, nday)\n",
    "            data_load_state.text('Loading data... done! ✔️')\n",
    "\n",
    "            st.markdown(\"**Tableau des valeurs prédictes**\")\n",
    "            st.write('Dimensions des données: ' + str(pred_station.shape[0]) + ' lignes & ' + str(pred_station.shape[1]) + ' colonnes')\n",
    "            st.write(pred_station)\n",
    "            csv = convert_df(pred_station)\n",
    "            st.download_button(\n",
    "                 label=\"Télécharger le tableau\",\n",
    "                 data=csv,\n",
    "                 file_name='pred_station.csv',\n",
    "                 mime='text/csv',\n",
    "             )\n",
    "            #st.markdown(filedownload(pred_station), unsafe_allow_html=True)\n",
    "\n",
    "\n",
    "            # visualisation_future_prediction\n",
    "\n",
    "            def visualisation_future_prediction(univariate_df, pred_station, look_back, nday):\n",
    "\n",
    "\n",
    "                new_df = pd.concat([univariate_df, pred_station]).reset_index(drop=True)\n",
    "\n",
    "                fig = go.Figure()\n",
    "                fig.add_trace(go.Scatter(x=new_df.iloc[len(univariate_df) - look_back:, 0], y=new_df.iloc[len(univariate_df) - look_back:, 1],  name= \"Hauteur d'eau réelle\"))\n",
    "                fig.add_trace(go.Scatter(x=new_df.iloc[len(univariate_df):,0], y= new_df.iloc[len(univariate_df):,1], name = \"Hauteur d'eau prévue\"))\n",
    "                fig.layout.update(title=\"Hauteur d'eau prévue dans \"+str(nday)+ \" jours\", title_x=0.5, \n",
    "                  xaxis=dict(\n",
    "                      rangeselector=dict(\n",
    "                          buttons=list([\n",
    "                              dict(count=1,\n",
    "                                  label='1m',\n",
    "                                  step='month',\n",
    "                                  stepmode='backward'),\n",
    "                              dict(count=6,\n",
    "                                  label='6m',\n",
    "                                  step='month',\n",
    "                                  stepmode='backward'),\n",
    "                              dict(count=12,\n",
    "                                  label='1y',\n",
    "                                  step='month',\n",
    "                                  stepmode='backward'),\n",
    "                              dict(count=36,\n",
    "                                  label='3y',\n",
    "                                  step='month',\n",
    "                                  stepmode='backward'),\n",
    "                              dict(step='all')\n",
    "                          ])\n",
    "                      ),\n",
    "                      rangeslider=dict(\n",
    "                          visible = True\n",
    "                      ),\n",
    "                      title='date'\n",
    "                  ),\n",
    "                  yaxis = dict(title=\"Hauteur d'eau\")\n",
    "              )\n",
    "                st.plotly_chart(fig)\n",
    "\n",
    "            st.markdown(\"**Visualisation des valeurs prédites**\")\n",
    "            visualisation_future_prediction(univariate_df, pred_station, 365, nday)\n",
    "    \n",
    "    \n",
    "            \n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "################################################################################################################################\n",
    "################################################ ARTICLE ################################################################\n",
    "################################################################################################################################    \n",
    "\n",
    "elif choose == \"Article\":\n",
    "            \n",
    "    st.markdown(\"\"\" <style> .font {\n",
    "        font-size:35px ; font-family: 'Cooper Black'; color: #FF9633;} \n",
    "        </style> \"\"\", unsafe_allow_html=True)\n",
    "    st.markdown('<p class=\"font\">Article</p>', unsafe_allow_html=True)\n",
    "    #with st.expander(label=\"Veuillez cliquer pour déplier/replier\"):\n",
    "        \n",
    "\n",
    "    st.markdown(\"\"\"\n",
    "        Veuilez cliquer sur le lien ci-dessous pour accéder à l'artilce\n",
    "         \n",
    "        * **Article:** [https://github.com](https://github.com/AYLY92/memoire/tree/main/Rapport)\n",
    "        \n",
    "        \"\"\")\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "################################################################################################################################\n",
    "################################################ CODE SOURCE ##########################################################################\n",
    "################################################################################################################################\n",
    "\n",
    "elif choose == \"Code source\":\n",
    "            \n",
    "    st.markdown(\"\"\" <style> .font {\n",
    "        font-size:35px ; font-family: 'Cooper Black'; color: #FF9633;} \n",
    "        </style> \"\"\", unsafe_allow_html=True)\n",
    "    st.markdown('<p class=\"font\">Code source</p>', unsafe_allow_html=True)\n",
    "    st.markdown(\"\"\"\n",
    "         Veuillez cliquer sur le lien ci-dessous pour accéder au code source.\n",
    "\n",
    "        * **Code source:** [https://github.com](https://github.com/AYLY92/memoire/tree/main/code%20source)\n",
    "        \"\"\")\n",
    "    \n",
    "     \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": None,
   "id": "8895974f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
